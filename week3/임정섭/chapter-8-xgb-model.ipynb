{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-04-06T14:31:13.273972Z",
     "iopub.execute_input": "2023-04-06T14:31:13.274511Z",
     "iopub.status.idle": "2023-04-06T14:31:13.285772Z",
     "shell.execute_reply.started": "2023-04-06T14:31:13.274457Z",
     "shell.execute_reply": "2023-04-06T14:31:13.284220Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": "/kaggle/input/porto-seguro-safe-driver-prediction/sample_submission.csv\n/kaggle/input/porto-seguro-safe-driver-prediction/train.csv\n/kaggle/input/porto-seguro-safe-driver-prediction/test.csv\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# 데이터 경로\ndata_path = '/kaggle/input/porto-seguro-safe-driver-prediction/'\n\ntrain = pd.read_csv(data_path + 'train.csv', index_col='id')\ntest = pd.read_csv(data_path + 'test.csv', index_col='id')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv', index_col='id')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T14:31:13.767286Z",
     "iopub.execute_input": "2023-04-06T14:31:13.768069Z",
     "iopub.status.idle": "2023-04-06T14:31:27.156538Z",
     "shell.execute_reply.started": "2023-04-06T14:31:13.768013Z",
     "shell.execute_reply": "2023-04-06T14:31:27.155266Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "all_data = pd.concat([train, test], ignore_index=True)\nall_data = all_data.drop('target', axis=1) # 타깃값 제거\n\nall_features = all_data.columns # 전체 피처",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T14:31:27.158383Z",
     "iopub.execute_input": "2023-04-06T14:31:27.158784Z",
     "iopub.status.idle": "2023-04-06T14:31:28.549964Z",
     "shell.execute_reply.started": "2023-04-06T14:31:27.158749Z",
     "shell.execute_reply": "2023-04-06T14:31:28.548813Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from sklearn.preprocessing import OneHotEncoder\n\n# 명목형 피처\ncat_features = [feature for feature in all_features if 'cat' in feature]\n\n# 원-핫 인코딩 적용\nonehot_encoder = OneHotEncoder()\nencoded_cat_matrix = onehot_encoder.fit_transform(all_data[cat_features]) ",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T14:31:37.637596Z",
     "iopub.execute_input": "2023-04-06T14:31:37.638396Z",
     "iopub.status.idle": "2023-04-06T14:31:40.107958Z",
     "shell.execute_reply.started": "2023-04-06T14:31:37.638345Z",
     "shell.execute_reply": "2023-04-06T14:31:40.106745Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# '데이터 하나당 결측값 개수'를 파생 피처로 추가\nall_data['num_missing'] = (all_data==-1).sum(axis=1)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T14:31:40.110317Z",
     "iopub.execute_input": "2023-04-06T14:31:40.111252Z",
     "iopub.status.idle": "2023-04-06T14:31:40.331272Z",
     "shell.execute_reply.started": "2023-04-06T14:31:40.111195Z",
     "shell.execute_reply": "2023-04-06T14:31:40.329994Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 명목형 피처, calc 분류 피처를 제외한 피처\nremaining_features = [feature for feature in all_features\n                      if ('cat' not in feature and 'calc' not in feature)] \n# num_missing을 remaining_features에 추가\nremaining_features.append('num_missing')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T14:31:46.052759Z",
     "iopub.execute_input": "2023-04-06T14:31:46.053186Z",
     "iopub.status.idle": "2023-04-06T14:31:46.060367Z",
     "shell.execute_reply.started": "2023-04-06T14:31:46.053150Z",
     "shell.execute_reply": "2023-04-06T14:31:46.058960Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 분류가 ind인 피처\nind_features = [feature for feature in all_features if 'ind' in feature]\n\nis_first_feature = True\nfor ind_feature in ind_features:\n    if is_first_feature:\n        all_data['mix_ind'] = all_data[ind_feature].astype(str) + '_'\n        is_first_feature = False\n    else:\n        all_data['mix_ind'] += all_data[ind_feature].astype(str) + '_'",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T14:31:54.192342Z",
     "iopub.execute_input": "2023-04-06T14:31:54.192822Z",
     "iopub.status.idle": "2023-04-06T14:32:16.769301Z",
     "shell.execute_reply.started": "2023-04-06T14:31:54.192780Z",
     "shell.execute_reply": "2023-04-06T14:32:16.767992Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "all_data['mix_ind']",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T14:32:16.771598Z",
     "iopub.execute_input": "2023-04-06T14:32:16.772008Z",
     "iopub.status.idle": "2023-04-06T14:32:16.783211Z",
     "shell.execute_reply.started": "2023-04-06T14:32:16.771965Z",
     "shell.execute_reply": "2023-04-06T14:32:16.781888Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "execution_count": 9,
     "output_type": "execute_result",
     "data": {
      "text/plain": "0          2_2_5_1_0_0_1_0_0_0_0_0_0_0_11_0_1_0_\n1           1_1_7_0_0_0_0_1_0_0_0_0_0_0_3_0_0_1_\n2          5_4_9_1_0_0_0_1_0_0_0_0_0_0_12_1_0_0_\n3           0_1_2_0_0_1_0_0_0_0_0_0_0_0_8_1_0_0_\n4           0_2_0_1_0_1_0_0_0_0_0_0_0_0_9_1_0_0_\n                           ...                  \n1488023     0_1_6_0_0_0_1_0_0_0_0_0_0_0_2_0_0_1_\n1488024    5_3_5_1_0_0_0_1_0_0_0_0_0_0_11_1_0_0_\n1488025     0_1_5_0_0_1_0_0_0_0_0_0_0_0_5_0_0_1_\n1488026    6_1_5_1_0_0_0_0_1_0_0_0_0_0_13_1_0_0_\n1488027    7_1_4_1_0_0_0_0_1_0_0_0_0_0_12_1_0_0_\nName: mix_ind, Length: 1488028, dtype: object"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "cat_count_features = []\nfor feature in cat_features+['mix_ind']:\n    val_counts_dict = all_data[feature].value_counts().to_dict()\n    all_data[f'{feature}_count'] = all_data[feature].apply(lambda x: \n                                                           val_counts_dict[x])\n    cat_count_features.append(f'{feature}_count')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T14:32:16.784500Z",
     "iopub.execute_input": "2023-04-06T14:32:16.784905Z",
     "iopub.status.idle": "2023-04-06T14:32:26.737106Z",
     "shell.execute_reply.started": "2023-04-06T14:32:16.784872Z",
     "shell.execute_reply": "2023-04-06T14:32:26.735911Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from scipy import sparse\n\n# 필요 없는 피처들\ndrop_features = ['ps_ind_14', 'ps_ind_10_bin', 'ps_ind_11_bin', \n                 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_car_14']\n\n# remaining_features, cat_count_features에서 drop_features를 제거한 데이터\nall_data_remaining = all_data[remaining_features+cat_count_features].drop(drop_features, axis=1)\n\n# 데이터 합치기\nall_data_sprs = sparse.hstack([sparse.csr_matrix(all_data_remaining),\n                               encoded_cat_matrix],\n                              format='csr')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T14:32:26.738711Z",
     "iopub.execute_input": "2023-04-06T14:32:26.739029Z",
     "iopub.status.idle": "2023-04-06T14:32:33.073263Z",
     "shell.execute_reply.started": "2023-04-06T14:32:26.738999Z",
     "shell.execute_reply": "2023-04-06T14:32:33.071884Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "num_train = len(train) # 훈련 데이터 개수\n\n# 훈련 데이터와 테스트 데이터 나누기\nX = all_data_sprs[:num_train]\nX_test = all_data_sprs[num_train:]\n\ny = train['target'].values\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T14:32:33.075133Z",
     "iopub.execute_input": "2023-04-06T14:32:33.075503Z",
     "iopub.status.idle": "2023-04-06T14:32:34.299265Z",
     "shell.execute_reply.started": "2023-04-06T14:32:33.075465Z",
     "shell.execute_reply": "2023-04-06T14:32:34.298018Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\n\ndef eval_gini(y_true, y_pred):\n    # 실제값과 예측값의 크기가 같은지 확인 (값이 다르면 오류 발생)\n    assert y_true.shape == y_pred.shape\n\n    n_samples = y_true.shape[0]                      # 데이터 개수\n    L_mid = np.linspace(1 / n_samples, 1, n_samples) # 대각선 값\n\n    # 1) 예측값에 대한 지니계수\n    pred_order = y_true[y_pred.argsort()] # y_pred 크기순으로 y_true 값 정렬\n    L_pred = np.cumsum(pred_order) / np.sum(pred_order) # 로렌츠 곡선\n    G_pred = np.sum(L_mid - L_pred)       # 예측 값에 대한 지니계수\n    import numpy as np\n\ndef eval_gini(y_true, y_pred):\n    # 실제값과 예측값의 크기가 같은지 확인 (값이 다르면 오류 발생)\n    assert y_true.shape == y_pred.shape\n\n    n_samples = y_true.shape[0]                      # 데이터 개수\n    L_mid = np.linspace(1 / n_samples, 1, n_samples) # 대각선 값\n\n    # 1) 예측값에 대한 지니계수\n    pred_order = y_true[y_pred.argsort()] # y_pred 크기순으로 y_true 값 정렬\n    L_pred = np.cumsum(pred_order) / np.sum(pred_order) # 로렌츠 곡선\n    G_pred = np.sum(L_mid - L_pred)       # 예측 값에 대한 지니계수\n\n    # 2) 예측이 완벽할 때 지니계수\n    true_order = y_true[y_true.argsort()] # y_true 크기순으로 y_true 값 정렬\n    L_true = np.cumsum(true_order) / np.sum(true_order) # 로렌츠 곡선\n    G_true = np.sum(L_mid - L_true)       # 예측이 완벽할 때 지니계수\n\n    # 정규화된 지니계수\n    return G_pred / G_true",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T14:33:02.024176Z",
     "iopub.execute_input": "2023-04-06T14:33:02.024618Z",
     "iopub.status.idle": "2023-04-06T14:33:02.035922Z",
     "shell.execute_reply.started": "2023-04-06T14:33:02.024573Z",
     "shell.execute_reply": "2023-04-06T14:33:02.034504Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# XGBoost용 gini() 함수\ndef gini(preds, dtrain):\n    labels = dtrain.get_label()\n    return 'gini', eval_gini(labels, preds)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T14:33:09.008540Z",
     "iopub.execute_input": "2023-04-06T14:33:09.009692Z",
     "iopub.status.idle": "2023-04-06T14:33:09.016036Z",
     "shell.execute_reply.started": "2023-04-06T14:33:09.009635Z",
     "shell.execute_reply": "2023-04-06T14:33:09.014504Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\n\n# 8:2 비율로 훈련 데이터, 검증 데이터 분리 (베이지안 최적화 수행용)\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, \n                                                      test_size=0.2, \n                                                      random_state=0)\n# 베이지안 최적화용 데이터셋\nbayes_dtrain = xgb.DMatrix(X_train, y_train)\nbayes_dvalid = xgb.DMatrix(X_valid, y_valid)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T14:33:27.606233Z",
     "iopub.execute_input": "2023-04-06T14:33:27.606653Z",
     "iopub.status.idle": "2023-04-06T14:33:28.546768Z",
     "shell.execute_reply.started": "2023-04-06T14:33:27.606616Z",
     "shell.execute_reply": "2023-04-06T14:33:28.545660Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 베이지안 최적화를 위한 하이퍼파라미터 범위\nparam_bounds = {'max_depth': (4, 8),\n                'subsample': (0.6, 0.9),\n                'colsample_bytree': (0.7, 1.0),\n                'min_child_weight': (5, 7),\n                'gamma': (8, 11),\n                'reg_alpha': (7, 9),\n                'reg_lambda': (1.1, 1.5),\n                'scale_pos_weight': (1.4, 1.6)}\n\n# 값이 고정된 하이퍼파라미터\nfixed_params = {'objective': 'binary:logistic',\n                'learning_rate': 0.02,\n                'random_state': 1991}",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T14:33:31.185264Z",
     "iopub.execute_input": "2023-04-06T14:33:31.185830Z",
     "iopub.status.idle": "2023-04-06T14:33:31.195650Z",
     "shell.execute_reply.started": "2023-04-06T14:33:31.185778Z",
     "shell.execute_reply": "2023-04-06T14:33:31.193959Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def eval_function(max_depth, subsample, colsample_bytree, min_child_weight,\n                 reg_alpha, gamma, reg_lambda, scale_pos_weight):\n    '''최적화하려는 평가지표(지니계수) 계산 함수'''\n    # 베이지안 최적화를 수행할 하이퍼파라미터\n    params = {'max_depth': int(round(max_depth)),\n              'subsample': subsample,\n              'colsample_bytree': colsample_bytree,\n              'min_child_weight': min_child_weight,\n              'gamma': gamma,\n              'reg_alpha':reg_alpha,\n              'reg_lambda': reg_lambda,\n              'scale_pos_weight': scale_pos_weight}\n    # 값이 고정된 하이퍼파라미터도 추가\n    params.update(fixed_params)\n    \n    print('하이퍼파라미터 :', params)    \n    # XGBoost 모델 훈련\n    xgb_model = xgb.train(params=params, \n                          dtrain=bayes_dtrain,\n                          num_boost_round=2000,\n                          evals=[(bayes_dvalid, 'bayes_dvalid')],\n                          maximize=True,\n                          feval=gini,\n                          early_stopping_rounds=200,\n                          verbose_eval=False)\n                           \n    best_iter = xgb_model.best_iteration # 최적 반복 횟수\n    # 검증 데이터로 예측 수행\n    preds = xgb_model.predict(bayes_dvalid, \n                              iteration_range=(0, best_iter))\n    # 지니계수 계산\n    gini_score = eval_gini(y_valid, preds)\n    print(f'지니계수 : {gini_score}\\n')\n    \n    return gini_score",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T14:34:00.620827Z",
     "iopub.execute_input": "2023-04-06T14:34:00.621265Z",
     "iopub.status.idle": "2023-04-06T14:34:00.632259Z",
     "shell.execute_reply.started": "2023-04-06T14:34:00.621231Z",
     "shell.execute_reply": "2023-04-06T14:34:00.630844Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from bayes_opt import BayesianOptimization\n\n# 베이지안 최적화 객체 생성\noptimizer = BayesianOptimization(f=eval_function, \n                                 pbounds=param_bounds, \n                                 random_state=0)\n\n# 베이지안 최적화 수행\noptimizer.maximize(init_points=3, n_iter=6)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T14:34:06.825204Z",
     "iopub.execute_input": "2023-04-06T14:34:06.825750Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "|   iter    |  target   | colsam... |   gamma   | max_depth | min_ch... | reg_alpha | reg_la... | scale_... | subsample |\n-------------------------------------------------------------------------------------------------------------------------\n하이퍼파라미터 : {'max_depth': 6, 'subsample': 0.867531900234624, 'colsample_bytree': 0.8646440511781974, 'min_child_weight': 6.0897663659937935, 'gamma': 10.14556809911726, 'reg_alpha': 7.84730959867781, 'reg_lambda': 1.3583576452266626, 'scale_pos_weight': 1.4875174422525386, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "지니계수 : 0.28470429444834217\n\n| \u001B[0m1        \u001B[0m | \u001B[0m0.2847   \u001B[0m | \u001B[0m0.8646   \u001B[0m | \u001B[0m10.15    \u001B[0m | \u001B[0m6.411    \u001B[0m | \u001B[0m6.09     \u001B[0m | \u001B[0m7.847    \u001B[0m | \u001B[0m1.358    \u001B[0m | \u001B[0m1.488    \u001B[0m | \u001B[0m0.8675   \u001B[0m |\n하이퍼파라미터 : {'max_depth': 7, 'subsample': 0.6261387899104622, 'colsample_bytree': 0.9890988281503088, 'min_child_weight': 6.0577898395058085, 'gamma': 9.150324556477333, 'reg_alpha': 8.136089122187865, 'reg_lambda': 1.4702386553170643, 'scale_pos_weight': 1.4142072116395774, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# 평가함수 점수가 최대일 때 하이퍼파라미터\nmax_params = optimizer.max['params']\nmax_params",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 정수형 하이퍼파라미터 변환\nmax_params['max_depth'] = int(round(max_params['max_depth']))\n\n# 값이 고정된 하이퍼파라미터 추가\nmax_params.update(fixed_params)\nmax_params",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from sklearn.model_selection import StratifiedKFold\n\n# 층화 K 폴드 교차 검증기 생성\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1991)\n\n# OOF 방식으로 훈련된 모델로 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\noof_val_preds = np.zeros(X.shape[0]) \n# OOF 방식으로 훈련된 모델로 테스트 데이터 타깃값을 예측한 확률을 담을 1차원 배열\noof_test_preds = np.zeros(X_test.shape[0]) \n\n# OOF 방식으로 모델 훈련, 검증, 예측\nfor idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n    # 각 폴드를 구분하는 문구 출력\n    print('#'*40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#'*40)\n        # 훈련용 데이터, 검증용 데이터 설정\n    X_train, y_train = X[train_idx], y[train_idx]\n    X_valid, y_valid = X[valid_idx], y[valid_idx]\n\n    # XGBoost 전용 데이터셋 생성 \n    dtrain = xgb.DMatrix(X_train, y_train)\n    dvalid = xgb.DMatrix(X_valid, y_valid)\n    dtest = xgb.DMatrix(X_test)\n    # XGBoost 모델 훈련\n    xgb_model = xgb.train(params=max_params, \n                          dtrain=dtrain,\n                          num_boost_round=2000,\n                          evals=[(dvalid, 'valid')],\n                          maximize=True,\n                          feval=gini,\n                          early_stopping_rounds=200,\n                          verbose_eval=100)\n    # 모델 성능이 가장 좋을 때의 부스팅 반복 횟수 저장\n    best_iter = xgb_model.best_iteration\n    # 테스트 데이터를 활용해 OOF 예측\n    oof_test_preds += xgb_model.predict(dtest,\n                                        iteration_range=(0, best_iter))/folds.n_splits\n    \n    # 모델 성능 평가를 위한 검증 데이터 타깃값 예측 \n    oof_val_preds[valid_idx] += xgb_model.predict(dvalid, \n                                                  iteration_range=(0, best_iter))\n    \n    # 검증 데이터 예측 확률에 대한 정규화 지니계수\n    gini_score = eval_gini(y_valid, oof_val_preds[valid_idx])\n    print(f'폴드 {idx+1} 지니계수 : {gini_score}\\n')",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print('OOF 검증 데이터 지니계수 :', eval_gini(y, oof_val_preds))",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "submission['target'] = oof_test_preds\nsubmission.to_csv('submission.csv')",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
