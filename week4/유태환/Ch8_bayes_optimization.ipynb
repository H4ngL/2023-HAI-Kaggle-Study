{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "bEy1xJTfqzSP",
        "outputId": "376f53eb-8145-4819-c444-ab5c85237ec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.9/dist-packages (1.5.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.9/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.9/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dcc20fe3-979c-4b08-8e1c-d1d359f77c8e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dcc20fe3-979c-4b08-8e1c-d1d359f77c8e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"taehwanyu\",\"key\":\"edd8b2baa6ff4299a16b9196435ada89\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Ege4ct23q0Fk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c porto-seguro-safe-driver-prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8tpwLhxrHIq",
        "outputId": "f377d6ee-1a60-4d0f-942a-81dc8b51dc0c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading porto-seguro-safe-driver-prediction.zip to /content\n",
            " 97% 74.0M/76.5M [00:00<00:00, 150MB/s]\n",
            "100% 76.5M/76.5M [00:00<00:00, 160MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip porto-seguro-safe-driver-prediction.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJKPUoUSrSEx",
        "outputId": "972e54f7-97f9-4043-ed00-0c5091c1c713"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  porto-seguro-safe-driver-prediction.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_path = './'\n",
        "\n",
        "train = pd.read_csv(data_path + 'train.csv', index_col='id')\n",
        "test = pd.read_csv(data_path + 'test.csv', index_col='id')\n",
        "submission = pd.read_csv(data_path + 'sample_submission.csv', index_col='id')"
      ],
      "metadata": {
        "id": "aFHR6LvwrWW4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = pd.concat([train, test], ignore_index=True)\n",
        "all_data = all_data.drop('target', axis=1)\n",
        "\n",
        "all_features = all_data.columns"
      ],
      "metadata": {
        "id": "iSSx9D0FrY5T"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "cat_features = [feature for feature in all_features if 'cat' in feature] \n",
        "\n",
        "onehot_encoder = OneHotEncoder()\n",
        "encoded_cat_matrix = onehot_encoder.fit_transform(all_data[cat_features]) "
      ],
      "metadata": {
        "id": "1YSYQ-XprpoP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data['num_missing'] = (all_data==-1).sum(axis=1)"
      ],
      "metadata": {
        "id": "bS7QQH9krufq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_features = [feature for feature in all_features\n",
        "                      if ('cat' not in feature and 'calc' not in feature)]\n",
        "remaining_features.append('num_missing')"
      ],
      "metadata": {
        "id": "KqOYjKJvr7Cm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind_features = [feature for feature in all_features if 'ind' in feature]"
      ],
      "metadata": {
        "id": "SYNVTTkxsQyn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_first_feature = True\n",
        "for ind_feature in ind_features:\n",
        "    if is_first_feature:\n",
        "        all_data['mix_ind'] = all_data[ind_feature].astype(str) + '_'\n",
        "        is_first_feature = False\n",
        "    else:\n",
        "        all_data['mix_ind'] += all_data[ind_feature].astype(str) + '_'\n",
        "\n",
        "all_data['mix_ind']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfX7HzGosWD3",
        "outputId": "5fe55fc7-dec1-40d9-bca5-75396535f1cf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          2_2_5_1_0_0_1_0_0_0_0_0_0_0_11_0_1_0_\n",
              "1           1_1_7_0_0_0_0_1_0_0_0_0_0_0_3_0_0_1_\n",
              "2          5_4_9_1_0_0_0_1_0_0_0_0_0_0_12_1_0_0_\n",
              "3           0_1_2_0_0_1_0_0_0_0_0_0_0_0_8_1_0_0_\n",
              "4           0_2_0_1_0_1_0_0_0_0_0_0_0_0_9_1_0_0_\n",
              "                           ...                  \n",
              "1488023     0_1_6_0_0_0_1_0_0_0_0_0_0_0_2_0_0_1_\n",
              "1488024    5_3_5_1_0_0_0_1_0_0_0_0_0_0_11_1_0_0_\n",
              "1488025     0_1_5_0_0_1_0_0_0_0_0_0_0_0_5_0_0_1_\n",
              "1488026    6_1_5_1_0_0_0_0_1_0_0_0_0_0_13_1_0_0_\n",
              "1488027    7_1_4_1_0_0_0_0_1_0_0_0_0_0_12_1_0_0_\n",
              "Name: mix_ind, Length: 1488028, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_count_features = []\n",
        "for feature in cat_features + ['mix_ind']:\n",
        "    val_counts_dict = all_data[feature].value_counts().to_dict()\n",
        "    all_data[f'{feature}_count'] = all_data[feature].apply(lambda x: val_counts_dict[x])\n",
        "    cat_count_features.append(f'{feature}_count')"
      ],
      "metadata": {
        "id": "lOZASLL7svAW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import sparse\n",
        "\n",
        "drop_features = ['ps_ind_14', 'ps_ind_10_bin', 'ps_ind_11_bin', \n",
        "                 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_car_14']\n",
        "\n",
        "all_data_remaining = all_data[remaining_features+cat_count_features].drop(drop_features, axis=1)\n",
        "\n",
        "all_data_sprs = sparse.hstack([sparse.csr_matrix(all_data_remaining), encoded_cat_matrix], format='csr')"
      ],
      "metadata": {
        "id": "kuf7ge3Rtb5U"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = len(train)\n",
        "\n",
        "X = all_data_sprs[:num_train]\n",
        "X_test = all_data_sprs[num_train:]\n",
        "\n",
        "y = train['target'].values"
      ],
      "metadata": {
        "id": "CnrBMVGAt2Po"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "bayes_dtrain = lgb.Dataset(X_train, y_train)\n",
        "bayes_dvalid = lgb.Dataset(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "VVfKNahEuCe5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_bounds = {'num_leaves': (30, 40),\n",
        "                'lambda_l1': (0.7, 0.9),\n",
        "                'lambda_l2': (0.9, 1),\n",
        "                'feature_fraction': (0.6, 0.7),\n",
        "                'bagging_fraction': (0.6, 0.9),\n",
        "                'min_child_samples': (6, 10),\n",
        "                'min_child_weight': (10, 40)}"
      ],
      "metadata": {
        "id": "4j7dDe8EuhAK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_params = {'objective': 'binary',\n",
        "                'learning_rate': 0.005,\n",
        "                'bagging_freq': 1,\n",
        "                'force_row_wise': True,\n",
        "                'random_state': 1991}"
      ],
      "metadata": {
        "id": "sEQ7X5Ztuk4Z"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def eval_gini(y_true, y_pred):\n",
        "    # 실제값과 예측값의 크기가 같은지 확인 (값이 다르면 오류 발생)\n",
        "    assert y_true.shape == y_pred.shape\n",
        "\n",
        "    n_samples = y_true.shape[0]                      # 데이터 개수\n",
        "    L_mid = np.linspace(1 / n_samples, 1, n_samples) # 대각선 값\n",
        "\n",
        "    # 1) 예측값에 대한 지니계수\n",
        "    pred_order = y_true[y_pred.argsort()] # y_pred 크기순으로 y_true 값 정렬\n",
        "    L_pred = np.cumsum(pred_order) / np.sum(pred_order) # 로렌츠 곡선\n",
        "    G_pred = np.sum(L_mid - L_pred)       # 예측 값에 대한 지니계수\n",
        "\n",
        "    # 2) 예측이 완벽할 때 지니계수\n",
        "    true_order = y_true[y_true.argsort()] # y_true 크기순으로 y_true 값 정렬\n",
        "    L_true = np.cumsum(true_order) / np.sum(true_order) # 로렌츠 곡선\n",
        "    G_true = np.sum(L_mid - L_true)       # 예측이 완벽할 때 지니계수\n",
        "\n",
        "    # 정규화된 지니계수\n",
        "    return G_pred / G_true\n",
        "\n",
        "def gini(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    return 'gini', eval_gini(labels, preds), True # 반환값"
      ],
      "metadata": {
        "id": "Yrs8Ri8MuqeY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_function(num_leaves, lambda_l1, lambda_l2, feature_fraction,\n",
        "                  bagging_fraction, min_child_samples, min_child_weight):\n",
        "    \n",
        "    params = {\n",
        "        'num_leaves': int(round(num_leaves)),\n",
        "        'lambda_l1': lambda_l1,\n",
        "        'lambda_l2': lambda_l2,\n",
        "        'feature_fraction': feature_fraction,\n",
        "        'bagging_fraction': bagging_fraction,\n",
        "        'min_child_samples': int(round(min_child_samples)),\n",
        "        'min_child_weight': min_child_weight,\n",
        "        'feature_pre_filter': False\n",
        "    }\n",
        "\n",
        "    params.update(fixed_params)\n",
        "    \n",
        "    print('하이퍼파라미터:', params)    \n",
        "    \n",
        "    lgb_model = lgb.train(params=params, \n",
        "                           train_set=bayes_dtrain,\n",
        "                           num_boost_round=2500,\n",
        "                           valid_sets=bayes_dvalid,\n",
        "                           feval=gini,\n",
        "                           early_stopping_rounds=300,\n",
        "                           verbose_eval=False)\n",
        "    \n",
        "    preds = lgb_model.predict(X_valid)\n",
        "    gini_score = eval_gini(y_valid, preds)\n",
        "    print(f'지니계수: {gini_score}\\n')\n",
        "    \n",
        "    return gini_score"
      ],
      "metadata": {
        "id": "xE3AaIm9u7Ay"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bayesian-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQrItKe2vpEt",
        "outputId": "0783f8dd-adeb-4fd7-aa61-953a3d1b3717"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian_optimization-1.4.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.9/dist-packages (from bayesian-optimization) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from bayesian-optimization) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from bayesian-optimization) (1.22.4)\n",
            "Collecting colorama>=0.4.6\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.1.1)\n",
            "Installing collected packages: colorama, bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.4.2 colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "optimizer = BayesianOptimization(f=eval_function, pbounds=param_bounds, random_state=0)\n",
        "optimizer.maximize(init_points=3, n_iter=6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5kPN5pMvRjD",
        "outputId": "b18269f8-4774-4d3a-f9bb-9c8cb3bd5ab8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   | baggin... | featur... | lambda_l1 | lambda_l2 | min_ch... | min_ch... | num_le... |\n",
            "-------------------------------------------------------------------------------------------------------------\n",
            "하이퍼파라미터: {'num_leaves': 34, 'lambda_l1': 0.8205526752143287, 'lambda_l2': 0.9544883182996897, 'feature_fraction': 0.6715189366372419, 'bagging_fraction': 0.7646440511781974, 'min_child_samples': 8, 'min_child_weight': 29.376823391999682, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
            "[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Total Bins 1555\n",
            "[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n",
            "[LightGBM] [Info] Start training from score -3.273091\n",
            "지니계수: 0.2855811556220905\n",
            "\n",
            "| \u001b[0m1        \u001b[0m | \u001b[0m0.2856   \u001b[0m | \u001b[0m0.7646   \u001b[0m | \u001b[0m0.6715   \u001b[0m | \u001b[0m0.8206   \u001b[0m | \u001b[0m0.9545   \u001b[0m | \u001b[0m7.695    \u001b[0m | \u001b[0m29.38    \u001b[0m | \u001b[0m34.38    \u001b[0m |\n",
            "하이퍼파라미터: {'num_leaves': 39, 'lambda_l1': 0.7766883037651555, 'lambda_l2': 0.9791725038082665, 'feature_fraction': 0.6963662760501029, 'bagging_fraction': 0.867531900234624, 'min_child_samples': 8, 'min_child_weight': 27.04133683281797, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
            "[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n",
            "[LightGBM] [Info] Total Bins 1555\n",
            "[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n",
            "[LightGBM] [Info] Start training from score -3.273091\n",
            "지니계수: 0.2837380537005777\n",
            "\n",
            "| \u001b[0m2        \u001b[0m | \u001b[0m0.2837   \u001b[0m | \u001b[0m0.8675   \u001b[0m | \u001b[0m0.6964   \u001b[0m | \u001b[0m0.7767   \u001b[0m | \u001b[0m0.9792   \u001b[0m | \u001b[0m8.116    \u001b[0m | \u001b[0m27.04    \u001b[0m | \u001b[0m39.26    \u001b[0m |\n",
            "하이퍼파라미터: {'num_leaves': 40, 'lambda_l1': 0.7040436794880651, 'lambda_l2': 0.9832619845547939, 'feature_fraction': 0.608712929970154, 'bagging_fraction': 0.6213108174593661, 'min_child_samples': 9, 'min_child_weight': 36.10036444740457, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
            "[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n",
            "[LightGBM] [Info] Total Bins 1555\n",
            "[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n",
            "[LightGBM] [Info] Start training from score -3.273091\n",
            "지니계수: 0.2857848354322048\n",
            "\n",
            "| \u001b[95m3        \u001b[0m | \u001b[95m0.2858   \u001b[0m | \u001b[95m0.6213   \u001b[0m | \u001b[95m0.6087   \u001b[0m | \u001b[95m0.704    \u001b[0m | \u001b[95m0.9833   \u001b[0m | \u001b[95m9.113    \u001b[0m | \u001b[95m36.1     \u001b[0m | \u001b[95m39.79    \u001b[0m |\n",
            "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.8444997594874222, 'lambda_l2': 0.9234023852202012, 'feature_fraction': 0.6593983245038058, 'bagging_fraction': 0.8977977822397395, 'min_child_samples': 9, 'min_child_weight': 10.549362495448534, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
            "[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Total Bins 1555\n",
            "[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n",
            "[LightGBM] [Info] Start training from score -3.273091\n",
            "지니계수: 0.2828993761731121\n",
            "\n",
            "| \u001b[0m4        \u001b[0m | \u001b[0m0.2829   \u001b[0m | \u001b[0m0.8978   \u001b[0m | \u001b[0m0.6594   \u001b[0m | \u001b[0m0.8445   \u001b[0m | \u001b[0m0.9234   \u001b[0m | \u001b[0m8.619    \u001b[0m | \u001b[0m10.55    \u001b[0m | \u001b[0m30.09    \u001b[0m |\n",
            "하이퍼파라미터: {'num_leaves': 37, 'lambda_l1': 0.7738449330497988, 'lambda_l2': 0.9032695189818599, 'feature_fraction': 0.6606341064409726, 'bagging_fraction': 0.7666713964943057, 'min_child_samples': 9, 'min_child_weight': 29.306172421380474, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
            "[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Total Bins 1555\n",
            "[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n",
            "[LightGBM] [Info] Start training from score -3.273091\n",
            "지니계수: 0.28513273331754563\n",
            "\n",
            "| \u001b[0m5        \u001b[0m | \u001b[0m0.2851   \u001b[0m | \u001b[0m0.7667   \u001b[0m | \u001b[0m0.6606   \u001b[0m | \u001b[0m0.7738   \u001b[0m | \u001b[0m0.9033   \u001b[0m | \u001b[0m8.769    \u001b[0m | \u001b[0m29.31    \u001b[0m | \u001b[0m36.6     \u001b[0m |\n",
            "하이퍼파라미터: {'num_leaves': 33, 'lambda_l1': 0.878140825240546, 'lambda_l2': 0.9, 'feature_fraction': 0.6949207801131031, 'bagging_fraction': 0.6580631827594777, 'min_child_samples': 10, 'min_child_weight': 35.85667779964393, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
            "[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Total Bins 1555\n",
            "[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n",
            "[LightGBM] [Info] Start training from score -3.273091\n",
            "지니계수: 0.28531708475434286\n",
            "\n",
            "| \u001b[0m6        \u001b[0m | \u001b[0m0.2853   \u001b[0m | \u001b[0m0.6581   \u001b[0m | \u001b[0m0.6949   \u001b[0m | \u001b[0m0.8781   \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m9.826    \u001b[0m | \u001b[0m35.86    \u001b[0m | \u001b[0m32.8     \u001b[0m |\n",
            "하이퍼파라미터: {'num_leaves': 37, 'lambda_l1': 0.8433793375135147, 'lambda_l2': 0.9479651949974717, 'feature_fraction': 0.6859622896374784, 'bagging_fraction': 0.8362539818721497, 'min_child_samples': 6, 'min_child_weight': 39.77484183530247, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
            "[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Total Bins 1555\n",
            "[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n",
            "[LightGBM] [Info] Start training from score -3.273091\n",
            "지니계수: 0.2854766974907317\n",
            "\n",
            "| \u001b[0m7        \u001b[0m | \u001b[0m0.2855   \u001b[0m | \u001b[0m0.8363   \u001b[0m | \u001b[0m0.686    \u001b[0m | \u001b[0m0.8434   \u001b[0m | \u001b[0m0.948    \u001b[0m | \u001b[0m6.002    \u001b[0m | \u001b[0m39.77    \u001b[0m | \u001b[0m36.8     \u001b[0m |\n",
            "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.7243619242443197, 'lambda_l2': 0.9, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'min_child_samples': 10, 'min_child_weight': 27.951241679061347, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
            "[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Total Bins 1555\n",
            "[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n",
            "[LightGBM] [Info] Start training from score -3.273091\n",
            "지니계수: 0.28455469364758784\n",
            "\n",
            "| \u001b[0m8        \u001b[0m | \u001b[0m0.2846   \u001b[0m | \u001b[0m0.6      \u001b[0m | \u001b[0m0.6      \u001b[0m | \u001b[0m0.7244   \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m27.95    \u001b[0m | \u001b[0m30.0     \u001b[0m |\n",
            "하이퍼파라미터: {'num_leaves': 36, 'lambda_l1': 0.7, 'lambda_l2': 1.0, 'feature_fraction': 0.7, 'bagging_fraction': 0.9, 'min_child_samples': 6, 'min_child_weight': 33.90131741687068, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
            "[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Total Bins 1555\n",
            "[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n",
            "[LightGBM] [Info] Start training from score -3.273091\n",
            "지니계수: 0.2840251406982248\n",
            "\n",
            "| \u001b[0m9        \u001b[0m | \u001b[0m0.284    \u001b[0m | \u001b[0m0.9      \u001b[0m | \u001b[0m0.7      \u001b[0m | \u001b[0m0.7      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.0      \u001b[0m | \u001b[0m33.9     \u001b[0m | \u001b[0m36.05    \u001b[0m |\n",
            "=============================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_params = optimizer.max['params']"
      ],
      "metadata": {
        "id": "SfiV0n-Av9cC"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_params['num_leaves'] = int(round(max_params['num_leaves']))\n",
        "max_params['min_child_samples'] = int(round(max_params['min_child_samples']))\n",
        "max_params.update(fixed_params)"
      ],
      "metadata": {
        "id": "a9ZA8uY8wEj2"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1991)\n",
        "\n",
        "oof_val_preds = np.zeros(X.shape[0])\n",
        "oof_test_preds = np.zeros(X_test.shape[0])"
      ],
      "metadata": {
        "id": "iLS2b0pCwv7F"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "for idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
        "    print(f'폴드 {idx + 1} / 폴드 {folds.n_splits}')\n",
        "    \n",
        "    X_train, y_train = X[train_idx], y[train_idx]\n",
        "    X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
        "    \n",
        "    dtrain = lgb.Dataset(X_train, y_train)\n",
        "    dvalid = lgb.Dataset(X_valid, y_valid)\n",
        "    \n",
        "    lgb_model = lgb.train(params=max_params,\n",
        "                          train_set=dtrain,\n",
        "                          num_boost_round=2500,\n",
        "                          valid_sets=dvalid,\n",
        "                          feval=gini,\n",
        "                          early_stopping_rounds=300,\n",
        "                          verbose_eval=100)\n",
        "    \n",
        "    oof_test_preds += lgb_model.predict(X_test)/folds.n_splits\n",
        "    oof_val_preds[valid_idx] += lgb_model.predict(X_valid)\n",
        "    \n",
        "    gini_score = eval_gini(y_valid, oof_val_preds[valid_idx])\n",
        "    print(f'폴드: {idx + 1}, 지니계수: {gini_score}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB27nwLlwwzx",
        "outputId": "ef812bd0-50b4-4818-a0ed-52be88be7387"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "폴드 1 / 폴드 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17355, number of negative: 458814\n",
            "[LightGBM] [Info] Total Bins 1554\n",
            "[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 216\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036447 -> initscore=-3.274764\n",
            "[LightGBM] [Info] Start training from score -3.274764\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.154239\tvalid_0's gini: 0.270944\n",
            "[200]\tvalid_0's binary_logloss: 0.153176\tvalid_0's gini: 0.275764\n",
            "[300]\tvalid_0's binary_logloss: 0.152584\tvalid_0's gini: 0.279501\n",
            "[400]\tvalid_0's binary_logloss: 0.152222\tvalid_0's gini: 0.282893\n",
            "[500]\tvalid_0's binary_logloss: 0.151986\tvalid_0's gini: 0.286058\n",
            "[600]\tvalid_0's binary_logloss: 0.151824\tvalid_0's gini: 0.288805\n",
            "[700]\tvalid_0's binary_logloss: 0.151712\tvalid_0's gini: 0.290719\n",
            "[800]\tvalid_0's binary_logloss: 0.151622\tvalid_0's gini: 0.292581\n",
            "[900]\tvalid_0's binary_logloss: 0.151552\tvalid_0's gini: 0.294212\n",
            "[1000]\tvalid_0's binary_logloss: 0.151505\tvalid_0's gini: 0.295204\n",
            "[1100]\tvalid_0's binary_logloss: 0.151471\tvalid_0's gini: 0.295909\n",
            "[1200]\tvalid_0's binary_logloss: 0.151438\tvalid_0's gini: 0.296721\n",
            "[1300]\tvalid_0's binary_logloss: 0.151414\tvalid_0's gini: 0.297335\n",
            "[1400]\tvalid_0's binary_logloss: 0.151402\tvalid_0's gini: 0.297569\n",
            "[1500]\tvalid_0's binary_logloss: 0.15139\tvalid_0's gini: 0.297881\n",
            "[1600]\tvalid_0's binary_logloss: 0.151382\tvalid_0's gini: 0.298033\n",
            "[1700]\tvalid_0's binary_logloss: 0.151376\tvalid_0's gini: 0.298238\n",
            "[1800]\tvalid_0's binary_logloss: 0.151372\tvalid_0's gini: 0.298342\n",
            "[1900]\tvalid_0's binary_logloss: 0.151369\tvalid_0's gini: 0.298371\n",
            "[2000]\tvalid_0's binary_logloss: 0.151371\tvalid_0's gini: 0.298222\n",
            "[2100]\tvalid_0's binary_logloss: 0.151362\tvalid_0's gini: 0.298463\n",
            "[2200]\tvalid_0's binary_logloss: 0.151359\tvalid_0's gini: 0.298466\n",
            "[2300]\tvalid_0's binary_logloss: 0.151362\tvalid_0's gini: 0.298415\n",
            "[2400]\tvalid_0's binary_logloss: 0.151359\tvalid_0's gini: 0.298569\n",
            "[2500]\tvalid_0's binary_logloss: 0.151361\tvalid_0's gini: 0.298542\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2458]\tvalid_0's binary_logloss: 0.151355\tvalid_0's gini: 0.29865\n",
            "폴드: 1, 지니계수: 0.2986504843987991\n",
            "\n",
            "폴드 2 / 폴드 5\n",
            "[LightGBM] [Info] Number of positive: 17355, number of negative: 458814\n",
            "[LightGBM] [Info] Total Bins 1560\n",
            "[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 216\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036447 -> initscore=-3.274764\n",
            "[LightGBM] [Info] Start training from score -3.274764\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.154347\tvalid_0's gini: 0.258575\n",
            "[200]\tvalid_0's binary_logloss: 0.153338\tvalid_0's gini: 0.263768\n",
            "[300]\tvalid_0's binary_logloss: 0.152804\tvalid_0's gini: 0.267635\n",
            "[400]\tvalid_0's binary_logloss: 0.152483\tvalid_0's gini: 0.271009\n",
            "[500]\tvalid_0's binary_logloss: 0.152299\tvalid_0's gini: 0.27324\n",
            "[600]\tvalid_0's binary_logloss: 0.152157\tvalid_0's gini: 0.275756\n",
            "[700]\tvalid_0's binary_logloss: 0.15206\tvalid_0's gini: 0.277655\n",
            "[800]\tvalid_0's binary_logloss: 0.151986\tvalid_0's gini: 0.279371\n",
            "[900]\tvalid_0's binary_logloss: 0.151942\tvalid_0's gini: 0.280359\n",
            "[1000]\tvalid_0's binary_logloss: 0.151898\tvalid_0's gini: 0.281475\n",
            "[1100]\tvalid_0's binary_logloss: 0.15186\tvalid_0's gini: 0.282482\n",
            "[1200]\tvalid_0's binary_logloss: 0.151835\tvalid_0's gini: 0.283198\n",
            "[1300]\tvalid_0's binary_logloss: 0.15181\tvalid_0's gini: 0.283848\n",
            "[1400]\tvalid_0's binary_logloss: 0.151796\tvalid_0's gini: 0.284221\n",
            "[1500]\tvalid_0's binary_logloss: 0.151781\tvalid_0's gini: 0.284645\n",
            "[1600]\tvalid_0's binary_logloss: 0.15177\tvalid_0's gini: 0.284943\n",
            "[1700]\tvalid_0's binary_logloss: 0.151761\tvalid_0's gini: 0.285129\n",
            "[1800]\tvalid_0's binary_logloss: 0.151755\tvalid_0's gini: 0.28522\n",
            "[1900]\tvalid_0's binary_logloss: 0.151752\tvalid_0's gini: 0.285325\n",
            "[2000]\tvalid_0's binary_logloss: 0.151749\tvalid_0's gini: 0.285504\n",
            "[2100]\tvalid_0's binary_logloss: 0.151748\tvalid_0's gini: 0.285633\n",
            "[2200]\tvalid_0's binary_logloss: 0.151744\tvalid_0's gini: 0.285711\n",
            "[2300]\tvalid_0's binary_logloss: 0.15174\tvalid_0's gini: 0.285853\n",
            "[2400]\tvalid_0's binary_logloss: 0.15174\tvalid_0's gini: 0.28594\n",
            "[2500]\tvalid_0's binary_logloss: 0.151745\tvalid_0's gini: 0.285916\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2334]\tvalid_0's binary_logloss: 0.151736\tvalid_0's gini: 0.285929\n",
            "폴드: 2, 지니계수: 0.2859292916021393\n",
            "\n",
            "폴드 3 / 폴드 5\n",
            "[LightGBM] [Info] Number of positive: 17356, number of negative: 458814\n",
            "[LightGBM] [Info] Total Bins 1558\n",
            "[LightGBM] [Info] Number of data points in the train set: 476170, number of used features: 217\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036449 -> initscore=-3.274707\n",
            "[LightGBM] [Info] Start training from score -3.274707\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.15424\tvalid_0's gini: 0.263985\n",
            "[200]\tvalid_0's binary_logloss: 0.153171\tvalid_0's gini: 0.268713\n",
            "[300]\tvalid_0's binary_logloss: 0.152574\tvalid_0's gini: 0.272773\n",
            "[400]\tvalid_0's binary_logloss: 0.152223\tvalid_0's gini: 0.275785\n",
            "[500]\tvalid_0's binary_logloss: 0.152001\tvalid_0's gini: 0.278098\n",
            "[600]\tvalid_0's binary_logloss: 0.151847\tvalid_0's gini: 0.280206\n",
            "[700]\tvalid_0's binary_logloss: 0.151748\tvalid_0's gini: 0.281603\n",
            "[800]\tvalid_0's binary_logloss: 0.151682\tvalid_0's gini: 0.282672\n",
            "[900]\tvalid_0's binary_logloss: 0.151637\tvalid_0's gini: 0.283423\n",
            "[1000]\tvalid_0's binary_logloss: 0.151608\tvalid_0's gini: 0.283963\n",
            "[1100]\tvalid_0's binary_logloss: 0.151589\tvalid_0's gini: 0.284105\n",
            "[1200]\tvalid_0's binary_logloss: 0.151574\tvalid_0's gini: 0.284387\n",
            "[1300]\tvalid_0's binary_logloss: 0.151575\tvalid_0's gini: 0.284318\n",
            "[1400]\tvalid_0's binary_logloss: 0.151572\tvalid_0's gini: 0.284372\n",
            "[1500]\tvalid_0's binary_logloss: 0.151569\tvalid_0's gini: 0.284466\n",
            "[1600]\tvalid_0's binary_logloss: 0.151574\tvalid_0's gini: 0.284435\n",
            "[1700]\tvalid_0's binary_logloss: 0.151579\tvalid_0's gini: 0.284362\n",
            "Early stopping, best iteration is:\n",
            "[1478]\tvalid_0's binary_logloss: 0.151568\tvalid_0's gini: 0.284492\n",
            "폴드: 3, 지니계수: 0.2844916047790675\n",
            "\n",
            "폴드 4 / 폴드 5\n",
            "[LightGBM] [Info] Number of positive: 17355, number of negative: 458815\n",
            "[LightGBM] [Info] Total Bins 1555\n",
            "[LightGBM] [Info] Number of data points in the train set: 476170, number of used features: 216\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036447 -> initscore=-3.274766\n",
            "[LightGBM] [Info] Start training from score -3.274766\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.154327\tvalid_0's gini: 0.256916\n",
            "[200]\tvalid_0's binary_logloss: 0.15331\tvalid_0's gini: 0.261871\n",
            "[300]\tvalid_0's binary_logloss: 0.152761\tvalid_0's gini: 0.265441\n",
            "[400]\tvalid_0's binary_logloss: 0.152441\tvalid_0's gini: 0.268613\n",
            "[500]\tvalid_0's binary_logloss: 0.152245\tvalid_0's gini: 0.271168\n",
            "[600]\tvalid_0's binary_logloss: 0.152098\tvalid_0's gini: 0.273746\n",
            "[700]\tvalid_0's binary_logloss: 0.152012\tvalid_0's gini: 0.275192\n",
            "[800]\tvalid_0's binary_logloss: 0.151952\tvalid_0's gini: 0.276278\n",
            "[900]\tvalid_0's binary_logloss: 0.151911\tvalid_0's gini: 0.277039\n",
            "[1000]\tvalid_0's binary_logloss: 0.151871\tvalid_0's gini: 0.277996\n",
            "[1100]\tvalid_0's binary_logloss: 0.151844\tvalid_0's gini: 0.278535\n",
            "[1200]\tvalid_0's binary_logloss: 0.151827\tvalid_0's gini: 0.279055\n",
            "[1300]\tvalid_0's binary_logloss: 0.151817\tvalid_0's gini: 0.27936\n",
            "[1400]\tvalid_0's binary_logloss: 0.151799\tvalid_0's gini: 0.279872\n",
            "[1500]\tvalid_0's binary_logloss: 0.151797\tvalid_0's gini: 0.280053\n",
            "[1600]\tvalid_0's binary_logloss: 0.151792\tvalid_0's gini: 0.280148\n",
            "[1700]\tvalid_0's binary_logloss: 0.151794\tvalid_0's gini: 0.280162\n",
            "[1800]\tvalid_0's binary_logloss: 0.151793\tvalid_0's gini: 0.280319\n",
            "[1900]\tvalid_0's binary_logloss: 0.151795\tvalid_0's gini: 0.280422\n",
            "[2000]\tvalid_0's binary_logloss: 0.151797\tvalid_0's gini: 0.280419\n",
            "[2100]\tvalid_0's binary_logloss: 0.151799\tvalid_0's gini: 0.280516\n",
            "Early stopping, best iteration is:\n",
            "[1852]\tvalid_0's binary_logloss: 0.15179\tvalid_0's gini: 0.280514\n",
            "폴드: 4, 지니계수: 0.2805136229288192\n",
            "\n",
            "폴드 5 / 폴드 5\n",
            "[LightGBM] [Info] Number of positive: 17355, number of negative: 458815\n",
            "[LightGBM] [Info] Total Bins 1558\n",
            "[LightGBM] [Info] Number of data points in the train set: 476170, number of used features: 217\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036447 -> initscore=-3.274766\n",
            "[LightGBM] [Info] Start training from score -3.274766\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.15439\tvalid_0's gini: 0.26681\n",
            "[200]\tvalid_0's binary_logloss: 0.15338\tvalid_0's gini: 0.272186\n",
            "[300]\tvalid_0's binary_logloss: 0.152821\tvalid_0's gini: 0.275897\n",
            "[400]\tvalid_0's binary_logloss: 0.1525\tvalid_0's gini: 0.278734\n",
            "[500]\tvalid_0's binary_logloss: 0.152277\tvalid_0's gini: 0.282151\n",
            "[600]\tvalid_0's binary_logloss: 0.15212\tvalid_0's gini: 0.285039\n",
            "[700]\tvalid_0's binary_logloss: 0.152009\tvalid_0's gini: 0.287435\n",
            "[800]\tvalid_0's binary_logloss: 0.15192\tvalid_0's gini: 0.289549\n",
            "[900]\tvalid_0's binary_logloss: 0.151862\tvalid_0's gini: 0.290886\n",
            "[1000]\tvalid_0's binary_logloss: 0.151819\tvalid_0's gini: 0.291935\n",
            "[1100]\tvalid_0's binary_logloss: 0.151782\tvalid_0's gini: 0.292972\n",
            "[1200]\tvalid_0's binary_logloss: 0.151752\tvalid_0's gini: 0.293784\n",
            "[1300]\tvalid_0's binary_logloss: 0.151732\tvalid_0's gini: 0.294315\n",
            "[1400]\tvalid_0's binary_logloss: 0.151724\tvalid_0's gini: 0.294475\n",
            "[1500]\tvalid_0's binary_logloss: 0.151713\tvalid_0's gini: 0.294786\n",
            "[1600]\tvalid_0's binary_logloss: 0.1517\tvalid_0's gini: 0.295146\n",
            "[1700]\tvalid_0's binary_logloss: 0.151694\tvalid_0's gini: 0.295268\n",
            "[1800]\tvalid_0's binary_logloss: 0.151695\tvalid_0's gini: 0.295212\n",
            "[1900]\tvalid_0's binary_logloss: 0.151689\tvalid_0's gini: 0.295454\n",
            "[2000]\tvalid_0's binary_logloss: 0.151693\tvalid_0's gini: 0.2954\n",
            "[2100]\tvalid_0's binary_logloss: 0.151694\tvalid_0's gini: 0.295427\n",
            "[2200]\tvalid_0's binary_logloss: 0.151692\tvalid_0's gini: 0.295538\n",
            "[2300]\tvalid_0's binary_logloss: 0.151699\tvalid_0's gini: 0.295411\n",
            "Early stopping, best iteration is:\n",
            "[2045]\tvalid_0's binary_logloss: 0.151689\tvalid_0's gini: 0.295553\n",
            "폴드: 5, 지니계수: 0.29555250456072807\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(eval_gini(y, oof_val_preds))\n",
        "\n",
        "submission['target'] = oof_test_preds\n",
        "submission.to_csv('submission.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvteCucLxPyl",
        "outputId": "02117fd5-654d-41ba-83bf-98bae783c2cf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2889651000887542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S7AMi294WhN3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}